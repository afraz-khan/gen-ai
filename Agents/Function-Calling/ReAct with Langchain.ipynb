{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReAct\n",
    "It's an agents pattern for LLMs where they are provided with a set of tools. Based on incoming questions, they reason to select the appropriate tool and provide it with relevant input to generate the required answer.\n",
    "Here, function incocation is not the responsiblity of the developer but rather the LLM.\n",
    "\n",
    "See [here](https://react-lm.github.io/)\n",
    "\n",
    "We take forward the same problem as discussed in the [Here](https://github.com/afraz-khan/gen-ai/blob/main/Agents/Function-Calling/Ollama%20%7C%20Local-Model.ipynb)\n",
    "\n",
    "#### Langchain wrapper\n",
    "LangChain has developed a standard API called _`create_react_agent`_ for building ReAct agents. It's essential to test and verify if your model supports this API before implementation. I used multiple local LLMs but [Claude-3.5-Sonnet](https://www.anthropic.com/news/claude-3-5-sonnet) testing was ranked top."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install Deps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor, create_openai_tools_agent, create_react_agent\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.tools import tool\n",
    "from langchain import hub\n",
    "from langchain.tools.render import render_text_description\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "from IPython.display import display, Markdown, Latex\n",
    "from langchain_aws import ChatBedrock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model=\"RichardErkhov/openai-community_-_gpt2-xl-gguf\",\n",
    "    temperature=0, api_key=\"lm-studio\",\n",
    "    base_url=\"http://localhost:1234/v1\"\n",
    ")\n",
    "\n",
    "llm = Ollama(model=\"llama3\", format='json')\n",
    "\n",
    "model_kwargs = {\n",
    "    \"temperature\": 0,\n",
    "    \"max_tokens\": 4096,\n",
    "    \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "    \"top_p\": 1,\n",
    "    \"top_k\": 50\n",
    "}\n",
    "llm = ChatBedrock(\n",
    "    model_id='anthropic.claude-3-5-sonnet-20240620-v1:0',\n",
    "    model_kwargs=model_kwargs,\n",
    "    region_name='us-east-1',\n",
    "    credentials_profile_name='default'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Tools and Calling Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PhoneNumberStatusCheckInput(BaseModel):\n",
    "    phone_number: str = Field(description=\"should be a phone number string\")\n",
    "\n",
    "class PhoneNumberReactivatorInput(BaseModel):\n",
    "    phone_number: str = Field(description=\"should be a phone number string\")\n",
    "\n",
    "class FinalMessageInput(BaseModel):\n",
    "    last_action_name: str = Field(description=\"should be the name of last executed action\")\n",
    "    last_action_output: dict = Field(default_factory=dict, description=\"should be python dictionary based the output from last executed action\")\n",
    "\n",
    "@tool(\"check-phone-number-status\", args_schema=PhoneNumberStatusCheckInput)\n",
    "def check_phone_number_status(phone_number: str):\n",
    "    \"\"\"Useful when you want to check the status of a phone number\"\"\"\n",
    "    phone_statuses = {\"1234567890\": True, \"0987654321\": False}\n",
    "    status = phone_statuses.get(phone_number, False)\n",
    "    return {\"active\": status}\n",
    "\n",
    "@tool(\"request-phone-number-reactivation\", args_schema=PhoneNumberReactivatorInput)\n",
    "def request_phone_number_reactivation(phone_number: str):\n",
    "    \"\"\"Useful when you want to submit a request to reactivate a phone number.\"\"\"\n",
    "    return {\"request_submitted\": True}\n",
    "\n",
    "@tool(\"prepare-final-message\", args_schema=FinalMessageInput, return_direct=True)\n",
    "def prepare_final_message(last_action_name: str, last_action_output: dict):\n",
    "    \"\"\"Useful when you want to create the final message for the user. Pass it arguments like {{\"last_action_name\": \"some-tool\", \"last_action_output\": {\"..key\": \"..val\"}}}\"\"\"\n",
    "\n",
    "    print(last_action_name, last_action_output)\n",
    "\n",
    "    if last_action_name == 'check-phone-number-status':\n",
    "        output = last_action_output['active']\n",
    "        if not output: return \"Your phone number is currently inactive. Do you want to reactivate it?\"\n",
    "        return \"Phone number is currently active.\"\n",
    "\n",
    "    if last_action_name == 'request-phone-number-reactivation':\n",
    "        output = last_action_output['request_submitted']\n",
    "        if not output: return \"Your request is submitted successfully.\"\n",
    "        return \"Cant submit your request.\"\n",
    "    \n",
    "    return {\"request_submitted\": True}\n",
    "\n",
    "tools = [check_phone_number_status, request_phone_number_reactivation]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I encountered a challenge with the `prepare_final_message` tool; the LLM didn't call it correctly. It seems that additional testing and fine-tuning are needed. However, ReAct functioned correctly with the other two tools and the use case questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = hub.pull(\"hwchase17/react\")\n",
    "\n",
    "agent = create_react_agent(llm, tools, prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Invoke Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an agent executor by passing in the agent and tools\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True, handle_parsing_errors=True)\n",
    "\n",
    "# question = \"check phone number status: 1234567890\"\n",
    "# question = \"check phone number status: 0987654321\"\n",
    "question = \"Please reactivate the phone number 0987654321\"\n",
    "\n",
    "response = agent_executor.invoke({\"input\": question, \"agent_scratchpad\" : [], \"chat_history\": []})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(response[\"output\"]))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
